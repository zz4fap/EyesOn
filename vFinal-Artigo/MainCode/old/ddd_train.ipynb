{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import csv\n",
    "import joblib\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=2, include_bias=True)\n",
    "\n",
    "# Read CSV data\n",
    "with open('calib_10xPonto/calib6/calibration10x_file17.csv', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    data = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TREINO RANDOM FOREST REGRESSOR\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import csv\n",
    "\n",
    "def load_and_convert_csv(file_path):\n",
    "    data = []\n",
    "    with open(file_path, newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            # Converte cada valor na linha para float\n",
    "            try:\n",
    "                converted_row = [float(value) for value in row]\n",
    "                data.append(converted_row)\n",
    "            except ValueError as e:\n",
    "                print(f\"Aviso: Não foi possível converter a linha {row}: {e}\")\n",
    "                continue\n",
    "    return np.array(data)  \n",
    "\n",
    "# Exemplo de uso:\n",
    "file_path = 'calib_10xPonto/calib10/calib_all_file10.csv'\n",
    "data = load_and_convert_csv(file_path)\n",
    "\n",
    "\n",
    "# Separando features (X) e targets (y)\n",
    "features = data[:, :2]  # Primeiras duas colunas\n",
    "target_X = data[:, 2]   # Terceira coluna (coordenada X)\n",
    "target_Y = data[:, 3]    # Quarta coluna (coordenada Y)\n",
    "\n",
    "# Dividindo em conjuntos de treino e teste (80% treino, 20% teste)\n",
    "X_train, X_test, y_X_train, y_X_test = train_test_split(features, target_X, test_size=0.2, random_state=42)\n",
    "_, _, y_Y_train, y_Y_test = train_test_split(features, target_Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Criando e treinando o modelo para coordenada X\n",
    "model_X = RandomForestRegressor(n_estimators=100)\n",
    "model_X.fit(X_train, y_X_train)\n",
    "\n",
    "# Criando e treinando o modelo para coordenada Y\n",
    "model_Y = RandomForestRegressor(n_estimators=100)\n",
    "model_Y.fit(X_train, y_Y_train)\n",
    "\n",
    "# Avaliando os modelos\n",
    "def evaluate_model(model, X_test, y_test, target_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"\\nAvaliação para {target_name}:\")\n",
    "    print(f\"MSE: {mse:.2f}\")\n",
    "    print(f\"R²: {r2:.2f}\")\n",
    "    return y_pred\n",
    "\n",
    "# Avaliando modelo X\n",
    "y_X_pred = evaluate_model(model_X, X_test, y_X_test, \"Coordenada X\")\n",
    "\n",
    "# Avaliando modelo Y\n",
    "y_Y_pred = evaluate_model(model_Y, X_test, y_Y_test, \"Coordenada Y\")\n",
    "joblib.dump(model_X, 'rf_regressorX.pkl')\n",
    "joblib.dump(model_Y, 'rf_regressorY.pkl')\n",
    "\n",
    "\n",
    "\n",
    "'''# Exemplo de previsão\n",
    "sample_input = np.array([[-0.3, -0.1]])  # Valores fictícios para demonstração\n",
    "pred_X = model_X.predict(sample_input)\n",
    "pred_Y = model_Y.predict(sample_input)\n",
    "print(f\"\\nExemplo de previsão para input {sample_input[0]}:\")\n",
    "print(f\"Coordenada X prevista: {pred_X[0]:.2f}\")\n",
    "print(f\"Coordenada Y prevista: {pred_Y[0]:.2f}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = np.array([[-0.3, -0.1]])  # Valores fictícios para demonstração\n",
    "pred_X = model_X.predict(sample_input)\n",
    "print(pred_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lendo o arquivo CSV original\n",
    "df = pd.read_csv('calib_10xPonto/calib9/calib_all_file9.csv', header=None, sep=',')\n",
    "\n",
    "# Verificando se leu corretamente\n",
    "if df.shape[1] != 4:\n",
    "    raise ValueError(f\"O arquivo deve ter 4 colunas, mas encontrou {df.shape[1]}\")\n",
    "\n",
    "# Nomeando as colunas\n",
    "df.columns = ['X', 'Y', 'Label_X', 'Label_Y']\n",
    "\n",
    "# Criando mapeamento de coordenadas para labels inteiros\n",
    "coordinate_pairs = list(zip(df['Label_X'], df['Label_Y']))\n",
    "unique_pairs = sorted(list(set(coordinate_pairs)))  # pares únicos ordenados\n",
    "label_map = {pair: i+1 for i, pair in enumerate(unique_pairs)}  # mapeia para 1, 2, 3,...\n",
    "\n",
    "# Criando nova coluna com labels inteiros\n",
    "df['Label'] = df.apply(lambda row: label_map[(row['Label_X'], row['Label_Y'])], axis=1)\n",
    "\n",
    "# Selecionando apenas as colunas X, Y e Label (removendo as originais de coordenadas)\n",
    "new_df = df[['X', 'Y', 'Label']]\n",
    "\n",
    "# Salvando o novo arquivo CSV\n",
    "new_filename = 'calib9_label.csv'\n",
    "new_df.to_csv(new_filename, index=False, header=False)\n",
    "\n",
    "print(f\"Arquivo '{new_filename}' criado com sucesso!\")\n",
    "print(\"\\nMapeamento utilizado:\")\n",
    "for pair, label in label_map.items():\n",
    "    print(f\"Coordenadas {pair} → Label {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLASSIFICAÇÃO\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# 1. Carregar os dados (assumindo o arquivo com labels inteiras que criamos)\n",
    "data = pd.read_csv('calib9_label.csv', header=None)\n",
    "X = data.iloc[:, :2].values  # Primeiras duas colunas (X e Y)\n",
    "y = data.iloc[:, 2].values   # Última coluna (Label)\n",
    "\n",
    "# 2. Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# 3. Criar e treinar o modelo\n",
    "model = RandomForestClassifier(n_estimators=30)  # 100 árvores\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Avaliar o modelo\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f\"Acurácia do modelo: {accuracy:.2%}\")\n",
    "\n",
    "# 5. Exemplo de previsão\n",
    "exemplo = [[-0.1, -0.05]]  # Valores de X e Y para predição\n",
    "predicao = model.predict(exemplo)\n",
    "print(f\"Predição para {exemplo}: classe {predicao[0]}\")\n",
    "joblib.dump(model, 'rf_classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort(key=lambda x: (float(x[2]), float(x[3])))\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definir o número de pontos por subplot\n",
    "points_per_plot = 30  # Você pode alterar esse valor para o número desejado\n",
    "\n",
    "# Número de linhas necessárias para plotar todos os subconjuntos em uma grade com 3 colunas\n",
    "rows = (len(data) + points_per_plot - 1) // points_per_plot // 3 + 1\n",
    "\n",
    "aux = 0\n",
    "# Criar uma figura com subplots\n",
    "fig, axes = plt.subplots(rows, 3, figsize=(15, rows*5))\n",
    "\n",
    "# Plotando todos os subconjuntos de dados necessários\n",
    "for index, ax in enumerate(axes.flatten()):\n",
    "    if index * points_per_plot < len(data):\n",
    "        # Definir o subconjunto de dados a ser plotado\n",
    "        info = data[index*points_per_plot:(index+1)*points_per_plot]\n",
    "\n",
    "        # Extrair os pontos de dados relevantes para plotar\n",
    "        x_values = [float(point[0]) for point in info]\n",
    "        y_values = [float(point[1]) for point in info]\n",
    "\n",
    "        # Plotar os pontos\n",
    "        ax.scatter(x_values, y_values, marker='o', color='blue')\n",
    "\n",
    "        # Definir rótulos e título\n",
    "        ax.set(xlabel='Pitch Values', ylabel='Yaw Values', title=f'{data[aux][2], data[aux][3]}')\n",
    "        aux += points_per_plot\n",
    "\n",
    "# Ajustar layout para evitar sobreposição\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar o plot\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_floats = [[ast.literal_eval(sublist) for sublist in group] for group in data]\n",
    "coord_x = [d[2] for d in data]\n",
    "coord_y = [d[3] for d in data]\n",
    "coord_x = list(map(int, map(float, coord_x)))  \n",
    "coord_y = list(map(int, map(float, coord_y)))  \n",
    "pitch_yaw = [(d[0], d[1]) for d in data_floats]\n",
    "\n",
    "print(coord_x)\n",
    "print(coord_y)\n",
    "print(pitch_yaw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_features = []\n",
    "\n",
    "for py in pitch_yaw:\n",
    "    py = np.array(py)\n",
    "    py = py.reshape(1, -1)\n",
    "    poly_features.append(poly.fit_transform(py))\n",
    "\n",
    "\n",
    "poly_features = np.array(poly_features)\n",
    "\n",
    "'''print(len(poly_features))\n",
    "print(poly_features.shape)\n",
    "print(poly_features)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(poly_features[0][0])\n",
    "poly_features2 = []\n",
    "for p in poly_features:\n",
    "    poly_features2.append(p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xx_train, Xx_test, Xy_train, Xy_test = train_test_split(poly_features2, coord_x, test_size=0.2)\n",
    "Yx_train, Yx_test, Yy_train, Yy_test = train_test_split(poly_features2, coord_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automlX = autosklearn.regression.AutoSklearnRegressor(\n",
    "    time_left_for_this_task=120,\n",
    "    per_run_time_limit=30,\n",
    "    tmp_folder=\"/tmp/autosklearnX_regression_example_tmp\",\n",
    ")\n",
    "automlY = autosklearn.regression.AutoSklearnRegressor(\n",
    "    time_left_for_this_task=120,\n",
    "    per_run_time_limit=30,\n",
    "    tmp_folder=\"/tmp/autosklearnY_regression_example_tmp\",\n",
    ")\n",
    "automlX.fit(Xx_train, Xy_train) #treinando modelo X\n",
    "automlY.fit(Yx_train, Yy_train) #treinando modelo X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVR\n",
    "tipo = 'rbf'\n",
    "svr_modelX = SVR(kernel=tipo, C=1000, gamma=0.1, epsilon=0.4)\n",
    "svr_modelY = SVR(kernel=tipo, C=1000, gamma=0.1, epsilon=0.4)\n",
    "\n",
    "svr_modelX.fit(Xx_train, Xy_train)\n",
    "svr_modelY.fit(Yx_train, Yy_train)\n",
    "\n",
    "# Fazendo previsões\n",
    "x_pred = svr_modelX.predict(Xx_test)\n",
    "y_pred = svr_modelY.predict(Yx_test)\n",
    "\n",
    "# Avaliação do modelo\n",
    "mseX = mean_squared_error(Xy_test, x_pred)\n",
    "mseY = mean_squared_error(Yy_test, y_pred)\n",
    "\n",
    "r2X = r2_score(Xy_test, y_pred)\n",
    "r2Y = r2_score(Yy_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"Mean Squared Error for X:\", mseX)\n",
    "print(\"Mean Squared Error for Y:\", mseY)\n",
    "print()\n",
    "print(\"R2 for X:\", r2X)\n",
    "print(\"R2 for Y:\", r2Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FOREST\n",
    "model_x = RandomForestRegressor(max_depth=6)\n",
    "model_y = RandomForestRegressor(max_depth=6)\n",
    "\n",
    "model_x.fit(Xx_train, Xy_train)\n",
    "model_y.fit(Yx_train, Yy_train)\n",
    "\n",
    "x_pred = model_x.predict(Xx_test)\n",
    "y_pred = model_y.predict(Yx_test)\n",
    "\n",
    "mse_x = mean_squared_error(Xy_test, x_pred)\n",
    "mse_y = mean_squared_error(Yy_test, y_pred)\n",
    "\n",
    "print()\n",
    "print(\"Ground Truth for X: \", Xy_test)\n",
    "print(\"Predictions for X:\", x_pred)\n",
    "print()\n",
    "print(\"Ground Truth for Y: \", Yy_test)\n",
    "print(\"Predictions for Y:\", y_pred)\n",
    "print()\n",
    "\n",
    "print(\"Mean Squared Error for X:\", mse_x)\n",
    "print(\"Mean Squared Error for Y:\", mse_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LINEAR REGRESSION\n",
    "model_x = LinearRegression()\n",
    "model_y = LinearRegression()\n",
    "\n",
    "model_x.fit(Xx_train, Xy_train)\n",
    "model_y.fit(Yx_train, Yy_train)\n",
    "\n",
    "x_pred = model_x.predict(Xx_test)\n",
    "y_pred = model_y.predict(Yx_test)\n",
    "\n",
    "mse_x = mean_squared_error(Xy_test, x_pred)\n",
    "mse_y = mean_squared_error(Yy_test, y_pred)\n",
    "\n",
    "print()\n",
    "print(\"Ground Truth for X: \", Xy_test)\n",
    "print(\"Predictions for X:\", x_pred)\n",
    "print()\n",
    "print(\"Ground Truth for Y: \", Yy_test)\n",
    "print(\"Predictions for Y:\", y_pred)\n",
    "print()\n",
    "\n",
    "print(\"Mean Squared Error for X:\", mse_x)\n",
    "print(\"Mean Squared Error for Y:\", mse_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(model_x, 'testeX.pkl')  # Save model_x\n",
    "#joblib.dump(model_y, 'testeY.pkl')  # Save model_y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
